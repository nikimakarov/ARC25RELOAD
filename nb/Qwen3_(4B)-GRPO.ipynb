{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikimakarov/ARC25RELOAD/blob/main/nb/Qwen3_(4B)-GRPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKUFULC_6Tgu"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkYbudwt6Tgw"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmdHMF5s6Tgw"
      },
      "source": [
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_path = os.getcwd()\n",
        "print(\"Current path:\", current_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y46tqlwbvaN",
        "outputId": "e041f600-9e85-4cfe-b343-17d8d3921687"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current path: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your ZIP file\n",
        "zip_path = \"ARC_RELOAD_V3.zip\"\n",
        "# Directory where you want to extract files\n",
        "extract_dir = \"ARC_RELOAD_V3\"\n",
        "\n",
        "# Make sure the output directory exists\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Extracted all files to '{extract_dir}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "NbYMEX7ja-KA",
        "outputId": "95bbfdce-aa3c-416b-d735-530acba5da81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-680697742.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Unzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracted all files to '{extract_dir}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gARis5P16Tgw"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LOKlviSQ6Tgw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\" # [NEW] Extra 30% context lengths!\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    # If you're not in Colab, just use pip install or uv pip install\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    pass # For Colab / Kaggle, we need extra instructions hidden below \\/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CadkLKl46Tgx"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "!pip install --upgrade -qqq uv\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    # If you're not in Colab, just use pip install!\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    try: import numpy; get_numpy = f\"numpy=={numpy.__version__}\"\n",
        "    except: get_numpy = \"numpy\"\n",
        "    try: import subprocess; is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n",
        "    except: is_t4 = False\n",
        "    get_vllm, get_triton = (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm==0.10.2\", \"triton\")\n",
        "    !uv pip install -qqq --upgrade \\\n",
        "        unsloth {get_vllm} {get_numpy} torchvision bitsandbytes xformers\n",
        "    !uv pip install -qqq {get_triton}\n",
        "!uv pip install transformers==4.55.4\n",
        "!uv pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkH_y8UC9lvv"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN75nmdx9lvw"
      },
      "source": [
        "Goal: To convert `Qwen3-4B-Base` into a reasoning model via GRPO by using OpenR1's Math dataset.\n",
        "\n",
        "We first pre fine-tune the model to make GRPO skip trying to match formatting - this speeds GRPO up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945,
          "referenced_widgets": [
            "4a4b7f4c5dc248d4aa5455b154cc2933",
            "3081f35f575f490c886563a4e1710ed1",
            "6a411d787f6e446fa5c5b16a97498e3f",
            "1708ff3764ad48818e66437321a1dc5c",
            "04953d72c39844bcaf4e548c91ce6b82",
            "b08a8a584bf7415a9070112106bf559e",
            "a9d3a9372b484d70a47eb79ffc32efd5",
            "b8515b8dab98454384da95ba95a62a59",
            "726cf36e1df04e719e9bbd6715845d7d",
            "18237675a20245e6afe80641f314d6f9",
            "e7dbc4d355224a99b196f82e3fe416e3",
            "c05b8081956a49659a5a8e0ebfab3642",
            "b7b8bd11685c48f6b5cc725743243d63",
            "0cd43bbdcc57491a8bcd2364ad058efb",
            "9020651020e74c70b5b6880afd6ae3dd",
            "1b62ca9855b04c38a6351c70f5784fd7",
            "a66631898cd848218e050004cf207cf3",
            "8e3786321af4453aabe1331a56fe541a",
            "b81516ad9fe0485d9706ee23d0b7a126",
            "920de4351a17413a8309e690288cbd14",
            "bb5bc0e3d1c648d3af048353263a95ee",
            "f22df68669f04d16865910aab04e3e5f"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "10cc3da0-efc3-44fa-8e78-dad5932b377f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao:Skipping import of cpp extensions due to incompatible torch version 2.7.0+cu126 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 10-14 21:28:10 [__init__.py:244] Automatically detected platform cuda.\n",
            "ERROR 10-14 21:28:15 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 10-14 21:28:35 [vllm_utils.py:689] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 10-14 21:28:35 [vllm_utils.py:717] Unsloth: Patching vLLM v0 graph capture\n",
            "==((====))==  Unsloth 2025.10.3: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.9.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/Qwen3-4B-Base with actual GPU utilization = 89.15%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 6.19 GB. Also swap space = 0 GB.\n",
            "INFO 10-14 21:29:00 [config.py:841] This model supports multiple tasks: {'embed', 'generate', 'classify', 'reward'}. Defaulting to 'generate'.\n",
            "WARNING 10-14 21:29:00 [config.py:3371] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 10-14 21:29:00 [config.py:1472] Using max model len 2048\n",
            "WARNING 10-14 21:29:00 [arg_utils.py:1735] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
            "INFO 10-14 21:29:02 [config.py:2285] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "INFO 10-14 21:29:02 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='unsloth/Qwen3-4B-Base', speculative_config=None, tokenizer='unsloth/Qwen3-4B-Base', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen3-4B-Base, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"max_capture_size\":192,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
            "INFO 10-14 21:29:03 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 10-14 21:29:03 [cuda.py:360] Using XFormers backend.\n",
            "INFO 10-14 21:29:04 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 10-14 21:29:04 [model_runner.py:1171] Starting to load model unsloth/Qwen3-4B-Base...\n",
            "INFO 10-14 21:29:06 [weight_utils.py:292] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a4b7f4c5dc248d4aa5455b154cc2933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 10-14 21:29:44 [default_loader.py:272] Loading weights took 37.89 seconds\n",
            "INFO 10-14 21:29:44 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
            "INFO 10-14 21:29:45 [model_runner.py:1203] Model loading took 7.6764 GiB and 39.458799 seconds\n",
            "INFO 10-14 21:29:52 [worker.py:294] Memory profiling takes 5.97 seconds\n",
            "INFO 10-14 21:29:52 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.89) = 13.14GiB\n",
            "INFO 10-14 21:29:52 [worker.py:294] model weights take 7.68GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 4.39GiB.\n",
            "INFO 10-14 21:29:52 [executor_base.py:113] # cuda blocks: 1996, # CPU blocks: 0\n",
            "INFO 10-14 21:29:52 [executor_base.py:118] Maximum concurrency for 2048 tokens per request: 15.59x\n",
            "INFO 10-14 21:29:53 [vllm_utils.py:722] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 10-14 21:29:53 [model_runner.py:1513] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Capturing CUDA graph shapes:   0%|          | 0/27 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c05b8081956a49659a5a8e0ebfab3642"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 10-14 21:30:00 [model_runner.py:1671] Graph capturing finished in 8 secs, took 0.31 GiB\n",
            "INFO 10-14 21:30:00 [vllm_utils.py:729] Unsloth: Patched vLLM v0 graph capture finished in 8 secs.\n",
            "INFO 10-14 21:30:02 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 16.53 seconds\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'layer_norm2', 'pre_feedforward_layernorm', 'layer_norm1', 'norm1', 'input_layernorm', 'k_norm', 'post_layernorm', 'norm2', 'q_norm', 'attention_norm', 'ffn_norm', 'post_attention_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'layer_norm2', 'pre_feedforward_layernorm', 'cross_attn_input_layernorm', 'layer_norm1', 'norm1', 'cross_attn_post_attention_layernorm', 'input_layernorm', 'k_norm', 'post_layernorm', 'norm2', 'q_norm', 'attention_norm', 'ffn_norm', 'post_attention_layernorm']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.10.3 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Can increase for longer reasoning traces\n",
        "lora_rank = 32 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-4B-Base\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = False, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.8, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
        "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mdsuGjxHrjT"
      },
      "source": [
        "### Pre fine-tuning for formatting\n",
        "We now use a subset of NVIDIA's [Open Math Reasoning dataset](https://huggingface.co/datasets/nvidia/OpenMathReasoning) which was filtered to only include high quality DeepSeek R1 traces.\n",
        "\n",
        "We'll only filter ~59 or so examples to first \"prime\" / pre fine-tune the model to understand our custom GRPO formatting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from accelerate.logging import get_logger\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "vH8HOLyLiS1e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to datasets\n",
        "DATASETS_DIR = '/content/ARC_RELOAD_V3/ARC_RELOAD_COPY_OCT_12/output/datasets_qwen25'\n",
        "\n",
        "TASK1_TRAIN = f'{DATASETS_DIR}/task1_train.parquet'\n",
        "TASK1_VAL = f'{DATASETS_DIR}/task1_validation.parquet'\n",
        "\n",
        "TASK2_TRAIN = f'{DATASETS_DIR}/task2_train.parquet'\n",
        "TASK2_VAL = f'{DATASETS_DIR}/task2_validation.parquet'\n",
        "\n",
        "# Load config from datasets\n",
        "with open(f'{DATASETS_DIR}/config.json', 'r') as f:\n",
        "    dataset_config = json.load(f)\n",
        "\n",
        "print(\"Dataset Configuration:\")\n",
        "print(f\"  Model: {dataset_config['model_path']}\")\n",
        "print(f\"  Grid Encoder: {dataset_config['grid_encoder']}\")\n",
        "print(f\"  Max Seq Len: {dataset_config['max_seq_len']}\")\n",
        "\n",
        "print(\"Loading Task 1 datasets...\")\n",
        "task1_train_df = pd.read_parquet(TASK1_TRAIN)\n",
        "task1_val_df = pd.read_parquet(TASK1_VAL)\n",
        "\n",
        "print(f\"  Task 1 Train: {len(task1_train_df)} samples\")\n",
        "print(f\"  Task 1 Val: {len(task1_val_df)} samples\")\n",
        "\n",
        "# Convert to HuggingFace Datasets (only text column needed for training)\n",
        "task1_train_dataset = Dataset.from_pandas(task1_train_df[['text']])\n",
        "task1_val_dataset = Dataset.from_pandas(task1_val_df[['text', 'ground_truth_output']])\n",
        "\n",
        "print(\"\\nTask 1 datasets ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOX7yfOjh7Sx",
        "outputId": "0f2570a0-3d2f-45b0-9412-33673aec8849"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Configuration:\n",
            "  Model: Qwen/Qwen2.5-0.5B-Instruct\n",
            "  Grid Encoder: GridShapeEncoder(RowNumberEncoder(MinimalGridEncoder()))\n",
            "  Max Seq Len: 4096\n",
            "Loading Task 1 datasets...\n",
            "  Task 1 Train: 974 samples\n",
            "  Task 1 Val: 124 samples\n",
            "\n",
            "Task 1 datasets ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g0fa--rikLD",
        "outputId": "7845f546-3daa-4227-b1a8-58e162828fc2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 974\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRsfMCRhitYu",
        "outputId": "2f0978f7-2f58-4d16-f755-0b76371651a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 974\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "train_dataset = pd.DataFrame(task1_train_dataset)  # or your ARC dataset\n",
        "eval_dataset = pd.DataFrame(task1_val_dataset)\n",
        "\n",
        "def format_arc(x):\n",
        "    text = x[\"text\"]\n",
        "    matches = re.findall(r\"<\\|im_start\\|\\>(.*?)\\n(.*?)<\\|im_end\\|\\>\", text, re.DOTALL)\n",
        "    messages = [{\"role\": role.strip(), \"content\": content.strip()} for role, content in matches]\n",
        "    return messages\n",
        "\n",
        "train_dataset[\"Messages\"] = train_dataset.apply(format_arc, axis=1)\n",
        "eval_dataset[\"Messages\"] = eval_dataset.apply(format_arc, axis=1)"
      ],
      "metadata": {
        "id": "jzjCEaAMjEGU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hWj9dMXkjW2B",
        "outputId": "f556fe1c-2f42-4d8a-b0f8-88fdd9f7f85f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "0    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "1    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "2    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "3    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "4    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "..                                                 ...   \n",
              "969  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "970  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "971  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "972  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "973  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "\n",
              "                                              Messages  \n",
              "0    [{'role': 'system', 'content': 'You are a help...  \n",
              "1    [{'role': 'system', 'content': 'You are a help...  \n",
              "2    [{'role': 'system', 'content': 'You are a help...  \n",
              "3    [{'role': 'system', 'content': 'You are a help...  \n",
              "4    [{'role': 'system', 'content': 'You are a help...  \n",
              "..                                                 ...  \n",
              "969  [{'role': 'system', 'content': 'You are a help...  \n",
              "970  [{'role': 'system', 'content': 'You are a help...  \n",
              "971  [{'role': 'system', 'content': 'You are a help...  \n",
              "972  [{'role': 'system', 'content': 'You are a help...  \n",
              "973  [{'role': 'system', 'content': 'You are a help...  \n",
              "\n",
              "[974 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18cdf752-aae4-48c2-aca6-6e150fc319e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>974 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18cdf752-aae4-48c2-aca6-6e150fc319e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18cdf752-aae4-48c2-aca6-6e150fc319e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18cdf752-aae4-48c2-aca6-6e150fc319e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b0811a7c-d27c-4c93-898f-1c4183810b05\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0811a7c-d27c-4c93-898f-1c4183810b05')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b0811a7c-d27c-4c93-898f-1c4183810b05 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_dataset",
              "summary": "{\n  \"name\": \"train_dataset\",\n  \"rows\": 974,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 974,\n        \"samples\": [\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 10x10\\n1 0011111110\\n2 0011011110\\n3 0011010110\\n4 0011010110\\n5 0000000110\\n6 0000000000\\n7 0000002000\\n8 0000002000\\n9 0000002000\\n10 0000202000\\n```\\n\\n### Output\\n\\n```grid shape: 10x10\\n1 0011111110\\n2 0011211110\\n3 0011012110\\n4 0011012110\\n5 0000002110\\n6 0000002000\\n7 0000000000\\n8 0000000000\\n9 0000000000\\n10 0000000000\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 10x10\\n1 0011111000\\n2 0011111000\\n3 0011011000\\n4 0011011000\\n5 0000000000\\n6 0000000000\\n7 0000000000\\n8 0000200000\\n9 0000200000\\n10 0000200000\\n```\\n\\n### Output\\n\\n```grid shape: 10x10\\n1 0011111000\\n2 0011111000\\n3 0011211000\\n4 0011211000\\n5 0000200000\\n6 0000000000\\n7 0000000000\\n8 0000000000\\n9 0000000000\\n10 0000000000\\n```\\n\\n## Example 3\\n\\n### Input\\n\\n```grid shape: 10x10\\n1 0111111111\\n2 0110111111\\n3 0110111101\\n4 0110010101\\n5 0000000000\\n6 0000000000\\n7 0000002000\\n8 0002002020\\n9 0002202020\\n10 0002202020\\n```\\n\\n### Output\\n\\n```grid shape: 10x10\\n1 0111111111\\n2 0112111111\\n3 0112111121\\n4 0112212121\\n5 0000202020\\n6 0000002000\\n7 0000002000\\n8 0000000000\\n9 0000000000\\n10 0000000000\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 10x10\\n1 0111111111\\n2 0101111101\\n3 0101010101\\n4 0101000101\\n5 0001000021\\n6 0000000020\\n7 0000020020\\n8 0020020020\\n9 0020220020\\n10 0020222020\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 10x10\\n1 0111111111\\n2 0121111121\\n3 0121212121\\n4 0121220121\\n5 0001020021\\n6 0000020020\\n7 0000020020\\n8 0000000000\\n9 0000000000\\n10 0000000000\\n```<|im_end|>\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 16x16\\n1 2334080000000000\\n2 5555555555555555\\n3 0000000000000000\\n4 0000000000000000\\n5 0000000000000000\\n6 0000000000000000\\n7 0000000000000000\\n8 0000000000000000\\n9 0000000000000000\\n10 0000000000000000\\n11 0000000000000000\\n12 0000020000000000\\n13 0000000000000000\\n14 0000000000000000\\n15 0000000000000000\\n16 0000000000000000\\n```\\n\\n### Output\\n\\n```grid shape: 16x16\\n1 2334050000000000\\n2 5555555555555555\\n3 0000000000000000\\n4 0000000000000000\\n5 0000000000000000\\n6 0000000000000000\\n7 8888888888800000\\n8 8000000000800000\\n9 8044444440800000\\n10 8043333340800000\\n11 8043333340800000\\n12 8043323340800000\\n13 8043333340800000\\n14 8043333340800000\\n15 8044444440800000\\n16 8000000000800000\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 16x16\\n1 1236000000000000\\n2 5555555555555555\\n3 0000000000000000\\n4 0000000000000000\\n5 0000000000000000\\n6 0000000000000000\\n7 0000000000000000\\n8 0000000000000000\\n9 0000000000000000\\n10 0000001000000000\\n11 0000000000000000\\n12 0000000000000000\\n13 0000000000000000\\n14 0000000000000000\\n15 0000000000000000\\n16 0000000000000000\\n```\\n\\n### Output\\n\\n```grid shape: 16x16\\n1 1236000000000000\\n2 5555555555555555\\n3 0000000000000000\\n4 0000000000000000\\n5 0000000000000000\\n6 0000000000000000\\n7 0006666666000000\\n8 0006333336000000\\n9 0006322236000000\\n10 0006321236000000\\n11 0006322236000000\\n12 0006333336000000\\n13 0006666666000000\\n14 0000000000000000\\n15 0000000000000000\\n16 0000000000000000\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 16x16\\n1 3208100000000000\\n2 5555555555555555\\n3 0000000000000000\\n4 0000000000000000\\n5 0000000000000000\\n6 0000000000000000\\n7 0000000000000000\\n8 0000000000000000\\n9 0000000000000000\\n10 0000000000000000\\n11 0000000000300000\\n12 0000000000000000\\n13 0000000000000000\\n14 0000000000000000\\n15 0000000000000000\\n16 0000000000000000\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 16x16\\n1 3208100000000000\\n2 5555555555555555\\n3 0000000000000000\\n4 0000000000000000\\n5 0000000000000000\\n6 0000000000000000\\n7 0000001111111110\\n8 0000001888888810\\n9 0000001800000810\\n10 0000001802220810\\n11 0000001802320810\\n12 0000001802220810\\n13 0000001800000810\\n14 0000001888888810\\n15 0000001111111110\\n16 0000000000000000\\n```<|im_end|>\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 6x5\\n1 90099\\n2 00000\\n3 00909\\n4 00440\\n5 44400\\n6 40404\\n```\\n\\n### Output\\n\\n```grid shape: 3x5\\n1 60606\\n2 66600\\n3 60000\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 6x5\\n1 00990\\n2 99099\\n3 09000\\n4 44000\\n5 40444\\n6 04004\\n```\\n\\n### Output\\n\\n```grid shape: 3x5\\n1 66660\\n2 06600\\n3 00006\\n```\\n\\n## Example 3\\n\\n### Input\\n\\n```grid shape: 6x5\\n1 09900\\n2 90009\\n3 90000\\n4 00404\\n5 44040\\n6 40440\\n```\\n\\n### Output\\n\\n```grid shape: 3x5\\n1 06006\\n2 06066\\n3 00660\\n```\\n\\n## Example 4\\n\\n### Input\\n\\n```grid shape: 6x5\\n1 09000\\n2 09909\\n3 90009\\n4 44040\\n5 04440\\n6 44000\\n```\\n\\n### Output\\n\\n```grid shape: 3x5\\n1 60060\\n2 00066\\n3 06006\\n```\\n\\n## Example 5\\n\\n### Input\\n\\n```grid shape: 6x5\\n1 99090\\n2 90090\\n3 09999\\n4 40040\\n5 44044\\n6 44404\\n```\\n\\n### Output\\n\\n```grid shape: 3x5\\n1 06000\\n2 06006\\n3 60060\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 6x5\\n1 99090\\n2 00909\\n3 00099\\n4 44404\\n5 40444\\n6 44000\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 3x5\\n1 00666\\n2 60060\\n3 66066\\n```<|im_end|>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Messages\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "auSHw0O1j3qD",
        "outputId": "0f5fdaec-3b29-4fc4-bd89-bdd24a5203ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "0    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "1    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "2    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "3    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "4    <|im_start|>system\\nYou are a helpful assistan...   \n",
              "..                                                 ...   \n",
              "119  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "120  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "121  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "122  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "123  <|im_start|>system\\nYou are a helpful assistan...   \n",
              "\n",
              "                                   ground_truth_output  \\\n",
              "0    [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,...   \n",
              "1    [[0, 0, 5, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0],...   \n",
              "2    [[0, 1, 0, 2, 0, 7, 0, 5, 0, 0, 2, 0, 8, 0, 6,...   \n",
              "3    [[0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
              "4    [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
              "..                                                 ...   \n",
              "119  [[2, 3, 3, 3, 2, 3, 3, 3], [3, 2, 3, 2, 3, 2, ...   \n",
              "120  [[7, 7, 7, 3], [7, 7, 3, 7], [7, 6, 7, 8], [6,...   \n",
              "121  [[0, 0, 0, 6, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0,...   \n",
              "122  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, ...   \n",
              "123  [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [7, 7, ...   \n",
              "\n",
              "                                              Messages  \n",
              "0    [{'role': 'system', 'content': 'You are a help...  \n",
              "1    [{'role': 'system', 'content': 'You are a help...  \n",
              "2    [{'role': 'system', 'content': 'You are a help...  \n",
              "3    [{'role': 'system', 'content': 'You are a help...  \n",
              "4    [{'role': 'system', 'content': 'You are a help...  \n",
              "..                                                 ...  \n",
              "119  [{'role': 'system', 'content': 'You are a help...  \n",
              "120  [{'role': 'system', 'content': 'You are a help...  \n",
              "121  [{'role': 'system', 'content': 'You are a help...  \n",
              "122  [{'role': 'system', 'content': 'You are a help...  \n",
              "123  [{'role': 'system', 'content': 'You are a help...  \n",
              "\n",
              "[124 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32e24b4a-f531-487c-a2e4-401d5d80f1d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ground_truth_output</th>\n",
              "      <th>Messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[0, 0, 5, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0],...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[0, 1, 0, 2, 0, 7, 0, 5, 0, 0, 2, 0, 8, 0, 6,...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[2, 3, 3, 3, 2, 3, 3, 3], [3, 2, 3, 2, 3, 2, ...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[7, 7, 7, 3], [7, 7, 3, 7], [7, 6, 7, 8], [6,...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[0, 0, 0, 6, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0,...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, ...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
              "      <td>[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [7, 7, ...</td>\n",
              "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>124 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32e24b4a-f531-487c-a2e4-401d5d80f1d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32e24b4a-f531-487c-a2e4-401d5d80f1d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32e24b4a-f531-487c-a2e4-401d5d80f1d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fff9f2df-79b5-477b-9cc4-22012cc09226\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fff9f2df-79b5-477b-9cc4-22012cc09226')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fff9f2df-79b5-477b-9cc4-22012cc09226 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eval_dataset",
              "summary": "{\n  \"name\": \"eval_dataset\",\n  \"rows\": 124,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 124,\n        \"samples\": [\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 8x8\\n1 66666666\\n2 99996666\\n3 99996999\\n4 00006999\\n5 05506000\\n6 05506070\\n7 05506050\\n8 00006000\\n```\\n\\n### Output\\n\\n```grid shape: 8x8\\n1 66666666\\n2 99996666\\n3 00006999\\n4 07506000\\n5 05506070\\n6 05506070\\n7 00006000\\n8 66666666\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 17x17\\n1 66666666666666666\\n2 66669666690000066\\n3 66669666690555066\\n4 66669666690000066\\n5 66666666666666666\\n6 66666666666666666\\n7 66600000096666669\\n8 66605555096666669\\n9 66605555096666669\\n10 66600000096666669\\n11 66666666666666666\\n12 66666666666666666\\n13 96669000000066666\\n14 96669075555066666\\n15 96669077555066666\\n16 96669000000066666\\n17 66666666666666666\\n```\\n\\n### Output\\n\\n```grid shape: 17x17\\n1 66666666666666666\\n2 66669690000066666\\n3 66669690777066666\\n4 66669690000066666\\n5 66666666666666666\\n6 66666666666666666\\n7 66666666660000009\\n8 66666666660777709\\n9 66666666660577709\\n10 66666666660000009\\n11 66666666666666666\\n12 66666666666666666\\n13 90000000666666666\\n14 90777550666666666\\n15 90777750666666666\\n16 90000000666666666\\n17 66666666666666666\\n```\\n\\n## Example 3\\n\\n### Input\\n\\n```grid shape: 12x12\\n1 666666666666\\n2 666666666666\\n3 000009666696\\n4 055709666696\\n5 055709666696\\n6 055509666696\\n7 000009666696\\n8 666666666666\\n9 969000000066\\n10 969077777066\\n11 969077777066\\n12 969000000066\\n```\\n\\n### Output\\n\\n```grid shape: 12x12\\n1 666666666666\\n2 666666666666\\n3 666660000096\\n4 666660777096\\n5 666660577096\\n6 666660577096\\n7 666660000096\\n8 666666666666\\n9 969000000066\\n10 969077777066\\n11 969077777066\\n12 969000000066\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 26x26\\n1 66666666666000006666660000\\n2 66666666666055506666660770\\n3 66666666666055506666660770\\n4 69999999666055506666660770\\n5 66666666666055506666660770\\n6 66666666666055506666660770\\n7 66666666666055706666660770\\n8 66666666666000006666660770\\n9 66666666666999996666660770\\n10 66666666666666666666660770\\n11 66666666666666666666660770\\n12 66666666666666666666660770\\n13 69999999666666666666660770\\n14 60000000666666666666660000\\n15 60777770666666666999669999\\n16 60777770666666666666666666\\n17 60777750666666666666666666\\n18 60555550666666666666666666\\n19 60555550666666666999666666\\n20 60555550666666666000666666\\n21 60555550666666666070666666\\n22 60555550666666666070666666\\n23 60555550666666666050666666\\n24 60000000666999996050666666\\n25 66666666666666666050666666\\n26 66666666666666666000669999\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 26x26\\n1 66666666666666666666660000\\n2 66666666666666666666660770\\n3 66666666666666666666660770\\n4 69999999666666666666660770\\n5 60000000666666666666660770\\n6 60777770666666666666660770\\n7 60777770666666666666660770\\n8 60777770666666666666660770\\n9 60777770666666666666660770\\n10 60777550666666666666660770\\n11 60555550666666666666660770\\n12 60555550666666666666660770\\n13 60555550666666666666660770\\n14 60555550666666666666660000\\n15 60000000666666666999669999\\n16 66666666666000006999666666\\n17 66666666666055706000666666\\n18 66666666666077706070666666\\n19 66666666666077706070666666\\n20 66666666666077706070666666\\n21 66666666666077706070666666\\n22 66666666666077706070666666\\n23 66666666666000006000666666\\n24 66666666666999996666666666\\n25 66666666666666666666666666\\n26 66666666666666666666669999\\n```<|im_end|>\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 30x30\\n1 123411341234123412341234123412\\n2 412341234123412341234123412341\\n3 341111111111111111111111111111\\n4 231444444441234123412341134113\\n5 121410000434123412344444443412\\n6 411461116423412341241000042311\\n7 341400001412341234146000641214\\n8 131400001441231123140000044113\\n9 121400001434123412340000043412\\n10 411444444421412341240000142311\\n11 341234123411341234144444441214\\n12 131123412341134123412341234113\\n13 121111111111111111111111111112\\n14 412341234123412341234123412341\\n15 341234123412341214123411141234\\n16 234123412341234123412141214113\\n17 123412222222222222222222123412\\n18 412342234123412344444442412341\\n19 341232444444441240000042341234\\n20 234122400000434140000042214123\\n21 123412460002423440000042123412\\n22 412342400000412340000042412341\\n23 341232400000411240000042341234\\n24 234122420000434144444442234123\\n25 123112444444423412341232123412\\n26 412342222222222222222222112341\\n27 341234123412341134123412341234\\n28 234123412341234123412141234123\\n29 123412311234123412341234123412\\n30 412341234123412341234123412341\\n```\\n\\n### Output\\n\\n```grid shape: 5x5\\n1 00000\\n2 62222\\n3 20000\\n4 20000\\n5 20000\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 30x30\\n1 412304444444444301244123412401\\n2 124014301234124012301230123012\\n3 230124088888834123042301430123\\n4 301234180400804230123012341230\\n5 012304284400814301234423012301\\n6 123044480444824012341230123012\\n7 230124080400834123422222222223\\n8 301234188888844230122222222220\\n9 012304230123014301220123012321\\n10 123044401230124042321888888022\\n11 240144042301244123022800008123\\n12 301234123042304430124800008220\\n13 412304230123414401220800008321\\n14 123014301230124412321800008022\\n15 230124412304234123022888888123\\n16 301234423412304230423012301220\\n17 042304230123014301220123012321\\n18 123014341230124012324230123022\\n19 230124012301234143422401230123\\n20 301234123042304430123012304220\\n21 012304230123014301220123012321\\n22 123044401230124012321888888022\\n23 230124088888834123022800208123\\n24 301244184044804430123822208220\\n25 012304480044814301220800008321\\n26 123014484000824012321802208022\\n27 230144084044844123422888888123\\n28 301234188888804230123000000420\\n29 012304230123014301222222222221\\n30 123014444444444012304230423012\\n```\\n\\n### Output\\n\\n```grid shape: 4x4\\n1 2202\\n2 0002\\n3 2222\\n4 2002\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 30x30\\n1 346634663456365664566456365636\\n2 456333333333336366666666666645\\n3 563356366636533666646634563666\\n4 634365555555634563655555554663\\n5 345335000005636664550000055634\\n6 656345001005436365650000056645\\n7 563365018105636466350000053656\\n8 634365001005634563450000054666\\n9 345335000005336664550000055634\\n10 466345555555436365655555556645\\n11 563366345634533466346634666656\\n12 634363456345636563456346634663\\n13 345366663456336664563466345634\\n14 456345634563436365634563456645\\n15 563366365634633466345634563666\\n16 666366656346634563656645634663\\n17 646336563456335664563656345634\\n18 456345666563436665664666456645\\n19 563356646634533466346664563656\\n20 634363456345634566456365634663\\n21 345335555555335664555555555664\\n22 456365818185636365650000056646\\n23 663355180815536466350040053656\\n24 634365800085634563650424054663\\n25 645335180815336666550040055634\\n26 456345818185436365650000056645\\n27 563355555555533466355555553656\\n28 636363466345634566666666666663\\n29 345333333333336634563456365636\\n30 466345636563456345636563456345\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 5x5\\n1 24242\\n2 42024\\n3 20002\\n4 42024\\n5 24242\\n```<|im_end|>\\n\",\n          \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 12x20\\n1 88888888888888888777\\n2 88888888877777788222\\n3 88888888800070788777\\n4 88888888807000788777\\n5 87777788888888888888\\n6 87000088888888888888\\n7 87070088888888877788\\n8 87777788888888822788\\n9 87272288888888872788\\n10 87222788888888877748\\n11 87777788888888888448\\n12 88888888888888888888\\n```\\n\\n### Output\\n\\n```grid shape: 12x20\\n1 88888888888888888888\\n2 88888888888888888888\\n3 88888888888888888888\\n4 88888887777777777788\\n5 88888887000000070788\\n6 88888887070007000788\\n7 88888887777777777788\\n8 88888887272222222788\\n9 88888887222777772788\\n10 88888887777777777788\\n11 88888888888888888888\\n12 88888888888888888888\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 10x10\\n1 8888888888\\n2 8448889938\\n3 8433383338\\n4 8839983338\\n5 8839988888\\n6 8888888888\\n7 8333883998\\n8 8993883938\\n9 8993883338\\n10 8888888888\\n```\\n\\n### Output\\n\\n```grid shape: 10x10\\n1 8888888888\\n2 8888888888\\n3 8833333388\\n4 8839999388\\n5 8839999388\\n6 8839999388\\n7 8839333388\\n8 8833333388\\n9 8888888888\\n10 8888888888\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 20x20\\n1 88888888888888888888\\n2 88888899998888888448\\n3 88888833998888899948\\n4 99988893998888893988\\n5 93388833338888833988\\n6 93988893338888833988\\n7 93388833998888888888\\n8 93988899998888888888\\n9 93388888888889998888\\n10 99988888888889998888\\n11 88888888888889338888\\n12 88888888888883398888\\n13 88888888888883398888\\n14 88899988888889338888\\n15 88893988888889998888\\n16 88833388888888888888\\n17 88893388888888888888\\n18 88893388888339888888\\n19 88833388888339888888\\n20 88899988888999888888\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 20x20\\n1 88888888888888888888\\n2 88888888888888888888\\n3 88999999999999999988\\n4 88933339999993993988\\n5 88939939993333333988\\n6 88933333333993333988\\n7 88939933333993333988\\n8 88933339993333333988\\n9 88999999999999999988\\n10 88888888888888888888\\n11 88888888888888888888\\n12 88888888888888888888\\n13 88888888888888888888\\n14 88888888888888888888\\n15 88888888888888888888\\n16 88888888888888888888\\n17 88888888888888888888\\n18 88888888888888888888\\n19 88888888888888888888\\n20 88888888888888888888\\n```<|im_end|>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth_output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 124,\n        \"samples\": [\n          \"[[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 7, 7, 7, 7, 7, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 7, 7, 7, 7, 7, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 7, 7, 7, 7, 7, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 7, 7, 7, 7, 7, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 7, 7, 7, 5, 5, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 5, 5, 5, 5, 5, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 5, 5, 5, 5, 5, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 5, 5, 5, 5, 5, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 0], [6, 0, 5, 5, 5, 5, 5, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 9, 9, 6, 6, 9, 9, 9, 9], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 6, 9, 9, 9, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 5, 5, 7, 0, 6, 0, 0, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 7, 0, 6, 0, 7, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 7, 0, 6, 0, 7, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 7, 0, 6, 0, 7, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 7, 0, 6, 0, 7, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 7, 7, 7, 0, 6, 0, 7, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 6, 0, 0, 0, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 9, 9, 9, 9]]\",\n          \"[[2, 4, 2, 4, 2], [4, 2, 0, 2, 4], [2, 0, 0, 0, 2], [4, 2, 0, 2, 4], [2, 4, 2, 4, 2]]\",\n          \"[[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8], [8, 8, 9, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 3, 9, 9, 3, 9, 8, 8], [8, 8, 9, 3, 9, 9, 3, 9, 9, 9, 3, 3, 3, 3, 3, 3, 3, 9, 8, 8], [8, 8, 9, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 3, 3, 3, 3, 9, 8, 8], [8, 8, 9, 3, 9, 9, 3, 3, 3, 3, 3, 9, 9, 3, 3, 3, 3, 9, 8, 8], [8, 8, 9, 3, 3, 3, 3, 9, 9, 9, 3, 3, 3, 3, 3, 3, 3, 9, 8, 8], [8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Messages\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = (\n",
        "    \"{% for message in messages %}\"\n",
        "        \"<|im_start|>{{ message['role'] }}\\n\"\n",
        "        \"{{ message['content'] }}<|im_end|>\\n\"\n",
        "    \"{% endfor %}\"\n",
        "    \"{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"\n",
        ")\n",
        "\n",
        "tokenizer.chat_template = chat_template"
      ],
      "metadata": {
        "id": "R-d3PXOCkcRg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5NI47rOIRP2"
      },
      "source": [
        "Check to see if it worked:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[\"N\"] = train_dataset[\"Messages\"].apply(lambda x: len(tokenizer.apply_chat_template(x)))\n",
        "train_dataset = train_dataset.loc[train_dataset[\"N\"] <= max_seq_length/4].copy()\n",
        "train_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY3OL0MUjkun",
        "outputId": "c1ef584d-dc7e-4c7e-c159-6263ef739c79"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_dataset[\"N\"] = eval_dataset[\"Messages\"].apply(lambda x: len(tokenizer.apply_chat_template(x)))\n",
        "#eval_dataset.shape"
      ],
      "metadata": {
        "id": "oa6jAY5dk7pn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6NkUCAGIj8N"
      },
      "source": [
        "We then tokenize the messages and convert it to a Hugging Face compatible dataset format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rgdtiV_f5hx",
        "outputId": "d6287e81-25ef-4286-d3eb-8fe663d8171a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'Messages', 'N', '__index_level_0__'],\n",
              "    num_rows: 46\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset[\"text\"] = tokenizer.apply_chat_template(train_dataset[\"Messages\"].values.tolist(), tokenize = False)\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "rBAgtUqS1wJ8",
        "outputId": "f30f700e-a4b3-4250-b38c-d6edce33a1aa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2702704437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_dataset[\"text\"] = tokenizer.apply_chat_template(eval_dataset[\"Messages\"].values.tolist(), tokenize = False)\n",
        "#eval_dataset = Dataset.from_pandas(eval_dataset)\n",
        "#eval_dataset"
      ],
      "metadata": {
        "id": "8rPx55lWli-N"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAQJjQrYKzOk"
      },
      "source": [
        "Let's now pre fine-tune the model so it follows our custom GRPO formatting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "42f561905e7e4fcd9227a7ba7aca5bd7",
            "6f24cf098d014b11a3d1e96d5d263d0b",
            "4a34fa8b5ffa455eadf57c13e5ebf64f",
            "31f5c507625f4759910f64e103772d51",
            "9d77372fecdc47249081f7327c7638a3",
            "fde0b1358f2b49e4af519a9902670442",
            "3316354d566c4b64be8be80e29efe318",
            "ce594c09344843d4b2e6422fbe7afce6",
            "f72f37ea32654c4786fcf86c24d84e8e",
            "55b298da760a4be4bdb0c1b40c3f7c69",
            "da99ff7d57114391a9cfe09464961b83"
          ]
        },
        "id": "woYi0SSygpqp",
        "outputId": "912cef3e-d202-4246-90fb-21ec3ac5e536"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/46 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42f561905e7e4fcd9227a7ba7aca5bd7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        save_steps=100,\n",
        "        gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        warmup_ratio=0.05,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=4,\n",
        "        num_train_epochs = 2, # Set this for 1 full training run.\n",
        "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "l4-2v_bLhZuE",
        "outputId": "40b1b125-3932-4577-9a29-5718762972e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 46 | Num Epochs = 2 | Total steps = 12\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 66,060,288 of 4,088,528,384 (1.62% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 01:18, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.213400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.181600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.951200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.909300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.767600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.591000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.561300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.368600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.339900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.360900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=12, training_loss=0.7355785891413689, metrics={'train_runtime': 93.9776, 'train_samples_per_second': 0.979, 'train_steps_per_second': 0.128, 'total_flos': 1032624599162880.0, 'train_loss': 0.7355785891413689, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRMBNUBgLC8T"
      },
      "source": [
        "Let's check if the model has learnt to follow the custom format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9HJxrS76h3Ds",
        "outputId": "82c267ed-3c6e-4777-ed81-f0eda17a9897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Let's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\n",
            "Below there are some input-output grid examples that define the task.\n",
            "Your job is to understand the transformation between the input and the output and apply it to the test input grid.\n",
            "The transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\n",
            "\n",
            "## Example 1\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 79\n",
            "2 43\n",
            "```\n",
            "\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 797979\n",
            "2 434343\n",
            "3 979797\n",
            "4 343434\n",
            "5 797979\n",
            "6 434343\n",
            "```\n",
            "\n",
            "## Example 2\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 86\n",
            "2 64\n",
            "```\n",
            "\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 868686\n",
            "2 646464\n",
            "3 686868\n",
            "4 464646\n",
            "5 868686\n",
            "6 646464\n",
            "```\n",
            "\n",
            "## Test case\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 32\n",
            "2 78\n",
            "```<|im_end|>\n",
            "<|im_start|>assistant\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 323232\n",
            "2 787878\n",
            "3 232323\n",
            "4 878787\n",
            "5 323232\n",
            "6 787878\n",
            "```.EditorButton\n",
            "Below there are some input-output grid examples that define the task.\n",
            "Your job is to understand the transformation between the input and the output and apply it to the test input grid.\n",
            "The transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\n",
            "\n",
            "## Example 1\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 79\n",
            "2 43\n",
            "```\n",
            "\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 797979\n",
            "2 434343\n",
            "3 979797\n",
            "4 343434\n",
            "5 797979\n",
            "6 434343\n",
            "```\n",
            "\n",
            "## Example 2\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 86\n",
            "2 64\n",
            "```\n",
            "\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 868686\n",
            "2 646464\n",
            "3 686868\n",
            "4 464646\n",
            "5 868686\n",
            "6 646464\n",
            "```\n",
            "\n",
            "## Test case\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 32\n",
            "2 78\n",
            "```.EditorButton\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 323232\n",
            "2 787878\n",
            "3 232323\n",
            "4 878787\n",
            "5 323232\n",
            "6 787878\n",
            "```.EditorButton\n",
            "Below there are some input-output grid examples that define the task.\n",
            "Your job is to understand the transformation between the input and the output and apply it to the test input grid.\n",
            "The transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\n",
            "\n",
            "## Example 1\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 79\n",
            "2 43\n",
            "```\n",
            "\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 797979\n",
            "2 434343\n",
            "3 979797\n",
            "4 343434\n",
            "5 797979\n",
            "6 434343\n",
            "```\n",
            "\n",
            "## Example 2\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 86\n",
            "2 64\n",
            "```\n",
            "\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 868686\n",
            "2 646464\n",
            "3 686868\n",
            "4 464646\n",
            "5 868686\n",
            "6 646464\n",
            "```\n",
            "\n",
            "## Test case\n",
            "\n",
            "### Input\n",
            "\n",
            "```grid shape: 2x2\n",
            "1 32\n",
            "2 78\n",
            "```.EditorButton\n",
            "### Output\n",
            "\n",
            "```grid shape: 6x6\n",
            "1 323232\n",
            "2 787878\n",
            "3 232323\n",
            "4 878787\n",
            "5 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1594383391.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m _ = model.generate(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1971\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[0;31m# Mixed precision autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEVICE_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2616\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2617\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2618\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2619\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3599\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3600\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3601\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3603\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             outputs = fast_forward_inference(\n\u001b[0m\u001b[1;32m   1134\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward_inference_custom\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# residual = X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m             X = fast_rms_layernorm_inference(\n\u001b[0m\u001b[1;32m   1078\u001b[0m                 \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfast_rms_layernorm_inference\u001b[0;34m(self, X, XX, XX2, variance)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mXX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mtorch_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    train_dataset[0][\"Messages\"][:2],\n",
        "    tokenize = False,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        ")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
        "    temperature = 0,\n",
        "    max_new_tokens = 1024,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train_dataset"
      ],
      "metadata": {
        "id": "SQKgl4uX0PqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtZ3qGOALF95"
      },
      "source": [
        "Yes it did follow the formatting! Great! Let's remove some items before the GRPO step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSZ0DET7bob",
        "outputId": "233603f4-f4ae-4a64-eb92-ac9d46b274f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1281"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We're using Hugging Face's [Open R1 Math dataset](https://huggingface.co/datasets/open-r1/DAPO-Math-17k-Processed). You can also utilize OpenAI's famous [GSM8K dataset](https://huggingface.co/datasets/openai/gsm8k)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ8Zj0ZH3RK8",
        "outputId": "10d245e0-1c51-4497-bf22-ac6e0ae259c9"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 974\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hucFhah3UcR",
        "outputId": "6d395fae-ce08-4d51-f864-4c158bbf0427"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 2x2\\n1 79\\n2 43\\n```\\n\\n### Output\\n\\n```grid shape: 6x6\\n1 797979\\n2 434343\\n3 979797\\n4 343434\\n5 797979\\n6 434343\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 2x2\\n1 86\\n2 64\\n```\\n\\n### Output\\n\\n```grid shape: 6x6\\n1 868686\\n2 646464\\n3 686868\\n4 464646\\n5 868686\\n6 646464\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 2x2\\n1 32\\n2 78\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 6x6\\n1 323232\\n2 787878\\n3 232323\\n4 878787\\n5 323232\\n6 787878\\n```<|im_end|>\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lubYL1yy3TUJ",
        "outputId": "a83a2422-0b8d-4ee5-d43b-034af4bebd42"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'ground_truth_output'],\n",
              "    num_rows: 124\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1_val_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzcwDb4Y3WXt",
        "outputId": "80c2eacc-7ee7-4268-8734-5c30784f0485"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 5x13\\n1 3333333333333\\n2 3222222222223\\n3 3213131333123\\n4 3222222222223\\n5 3333333333333\\n```\\n\\n### Output\\n\\n```grid shape: 5x13\\n1 3333333333333\\n2 3222222222223\\n3 3213131313123\\n4 3222222222223\\n5 3333333333333\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 21x22\\n1 4444444444444444444444\\n2 4222222222222222222224\\n3 4233433433433433443324\\n4 4233433433433433443324\\n5 4222222222222222222224\\n6 4444444444444444444444\\n7 4222222222222222222224\\n8 4214141411141414141424\\n9 4241414141414141414124\\n10 4222222222222222222224\\n11 4444444444444444444444\\n12 4222222222222222222224\\n13 4284488488848884888424\\n14 4288448884888488848824\\n15 4222222222222222222224\\n16 4444444444444444444444\\n17 4222222222222222222224\\n18 4294949494949494949924\\n19 4294949499949494949424\\n20 4222222222222222222224\\n21 4444444444444444444444\\n```\\n\\n### Output\\n\\n```grid shape: 21x22\\n1 4444444444444444444444\\n2 4222222222222222222224\\n3 4233433433433433433424\\n4 4233433433433433433424\\n5 4222222222222222222224\\n6 4444444444444444444444\\n7 4222222222222222222224\\n8 4214141414141414141424\\n9 4241414141414141414124\\n10 4222222222222222222224\\n11 4444444444444444444444\\n12 4222222222222222222224\\n13 4284888488848884888424\\n14 4288848884888488848824\\n15 4222222222222222222224\\n16 4444444444444444444444\\n17 4222222222222222222224\\n18 4294949494949494949424\\n19 4294949494949494949424\\n20 4222222222222222222224\\n21 4444444444444444444444\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 29x29\\n1 88888888888888888888888888888\\n2 83333338333333833333383333338\\n3 83888838318883834488383888838\\n4 83822838381883834444383888838\\n5 83822838388183838884383899838\\n6 83888838388813834444383898838\\n7 83822838388183834888383888838\\n8 83822838381883834444383898838\\n9 83888838318883838884383899838\\n10 83822838381883834444383898838\\n11 83822838388183834888383888838\\n12 83888838388813834444383898838\\n13 83822838318183838884383899838\\n14 83822838381883834844383898838\\n15 83888838318883834888383888838\\n16 83822838381883834444383898838\\n17 83822838388183838884383899838\\n18 83888838388813834444383898838\\n19 83822838388183834888383888838\\n20 83822838381883834444383898838\\n21 83888838318883838884383899838\\n22 83822838381883834444383898838\\n23 83822838388183834888383888838\\n24 83888838388183834844383898838\\n25 83882838388183838884383899838\\n26 83822838381883834444383899838\\n27 83888838318883834888383888838\\n28 83333338333333833333383333338\\n29 88888888888888888888888888888\\n```<|im_end|>\\n<|im_start|>assistant\\n### Output\\n\\n```grid shape: 29x29\\n1 88888888888888888888888888888\\n2 83333338333333833333383333338\\n3 83888838318883834888383888838\\n4 83822838381883834444383898838\\n5 83822838388183838884383899838\\n6 83888838388813834444383898838\\n7 83822838388183834888383888838\\n8 83822838381883834444383898838\\n9 83888838318883838884383899838\\n10 83822838381883834444383898838\\n11 83822838388183834888383888838\\n12 83888838388813834444383898838\\n13 83822838388183838884383899838\\n14 83822838381883834444383898838\\n15 83888838318883834888383888838\\n16 83822838381883834444383898838\\n17 83822838388183838884383899838\\n18 83888838388813834444383898838\\n19 83822838388183834888383888838\\n20 83822838381883834444383898838\\n21 83888838318883838884383899838\\n22 83822838381883834444383898838\\n23 83822838388183834888383888838\\n24 83888838388813834444383898838\\n25 83822838388183838884383899838\\n26 83822838381883834444383898838\\n27 83888838318883834888383888838\\n28 83333338333333833333383333338\\n29 88888888888888888888888888888\\n```<|im_end|>\\n\",\n",
              " 'ground_truth_output': '[[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 1, 8, 8, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 8, 8, 8, 4, 3, 8, 3, 8, 9, 9, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 8, 8, 8, 1, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 1, 8, 8, 8, 3, 8, 3, 8, 8, 8, 4, 3, 8, 3, 8, 9, 9, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 8, 8, 8, 1, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 8, 8, 8, 4, 3, 8, 3, 8, 9, 9, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 1, 8, 8, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 8, 8, 8, 4, 3, 8, 3, 8, 9, 9, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 8, 8, 8, 1, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 1, 8, 8, 8, 3, 8, 3, 8, 8, 8, 4, 3, 8, 3, 8, 9, 9, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 8, 8, 8, 1, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 8, 1, 8, 3, 8, 3, 8, 8, 8, 4, 3, 8, 3, 8, 9, 9, 8, 3, 8], [8, 3, 8, 2, 2, 8, 3, 8, 3, 8, 1, 8, 8, 3, 8, 3, 4, 4, 4, 4, 3, 8, 3, 8, 9, 8, 8, 3, 8], [8, 3, 8, 8, 8, 8, 3, 8, 3, 1, 8, 8, 8, 3, 8, 3, 4, 8, 8, 8, 3, 8, 3, 8, 8, 8, 8, 3, 8], [8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 8], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]'}"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "ARC_GRID_PATTERN = re.compile(\n",
        "    r\"grid shape:\\s*\\d+x\\d+[\\s\\S]*?(?:\\d\\s[\\d\\s]+)+\",\n",
        "    flags=re.MULTILINE | re.IGNORECASE,\n",
        ")\n",
        "\n",
        "def _extract_response(completion):\n",
        "    \"\"\"Helper to handle both string and list[dict] completions.\"\"\"\n",
        "    if isinstance(completion, str):\n",
        "        return completion\n",
        "    elif isinstance(completion, list) and len(completion) > 0:\n",
        "        if isinstance(completion[0], dict) and \"content\" in completion[0]:\n",
        "            return completion[0][\"content\"]\n",
        "        elif isinstance(completion[0], str):\n",
        "            return completion[0]\n",
        "    return \"\"\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ FORMAT CHECKS\n",
        "# ============================================================\n",
        "\n",
        "def check_arc_format_exactly(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        response = _extract_response(completion)\n",
        "        scores.append(3.0 if ARC_GRID_PATTERN.search(response) else 0.0)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def check_arc_format_approximately(completions, **kwargs):\n",
        "    scores = []\n",
        "    for completion in completions:\n",
        "        response = _extract_response(completion)\n",
        "        score = 0.0\n",
        "        if \"grid shape\" in response: score += 0.5\n",
        "        if \"```\" in response: score += 0.5\n",
        "        if any(c.isdigit() for c in response): score += 0.5\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ ANSWER MATCHING\n",
        "# ============================================================\n",
        "\n",
        "def check_arc_answer(prompts, completions, answers, **kwargs):\n",
        "    scores = []\n",
        "    for completion, true_answer in zip(completions, answers):\n",
        "        response = _extract_response(completion)\n",
        "\n",
        "        gen_nums  = re.findall(r\"\\d+\", response)\n",
        "        true_nums = re.findall(r\"\\d+\", true_answer)\n",
        "\n",
        "        if not gen_nums or not true_nums:\n",
        "            scores.append(-2.0)\n",
        "            continue\n",
        "\n",
        "        overlap = sum(1 for g, t in zip(gen_nums, true_nums) if g == t)\n",
        "        ratio = overlap / max(len(true_nums), 1)\n",
        "\n",
        "        if ratio > 0.95: score = 5.0\n",
        "        elif ratio > 0.8: score = 3.0\n",
        "        elif ratio > 0.5: score = 1.0\n",
        "        else: score = -1.0\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ MAIN COMBINED FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def check_arc_overall(prompts, completions, **kwargs):\n",
        "    answers = kwargs.get(\"answer\", {})\n",
        "    print(answers)\n",
        "\n",
        "    # –í—ã—Ä–æ–≤–Ω—è—Ç—å –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ\n",
        "    min_len = min(len(completions), len(answers))\n",
        "    completions = completions[:min_len]\n",
        "    answers = answers[:min_len]\n",
        "\n",
        "    exact  = check_arc_format_exactly(completions)\n",
        "    approx = check_arc_format_approximately(completions)\n",
        "    grid   = check_arc_answer(prompts, completions, answers)\n",
        "    print(\"DATA:\")\n",
        "    print(prompts)\n",
        "    print(completions)\n",
        "    print(answers)\n",
        "\n",
        "    scores = [e + a + g for e, a, g in zip(exact, approx, grid)]\n",
        "    return scores"
      ],
      "metadata": {
        "id": "8Fq3ovQKtaCB"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare your datasets\n",
        "train_filtered, eval_filtered, max_train_len, max_eval_len = prepare_arc_dataset(\n",
        "    task1_train_dataset,\n",
        "    task1_val_dataset,\n",
        "    tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "YPivLBE3t0We",
        "outputId": "0fbc0609-6420-4c94-ee4b-c281979e80a2"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚û°Ô∏è Converting to Hugging Face Datasets...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object, got 'Series'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-446394985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare your datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_filtered, eval_filtered, max_train_len, max_eval_len = prepare_arc_dataset(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtask1_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtask1_val_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1996700485.py\u001b[0m in \u001b[0;36mprepare_arc_dataset\u001b[0;34m(train_input, eval_input, tokenizer)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Messages\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Messages\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_arc_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10399\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10400\u001b[0m         )\n\u001b[0;32m> 10401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10403\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-625839561.py\u001b[0m in \u001b[0;36mformat_arc_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformat_arc_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"<\\|im_start\\|\\>(.*?)\\n(.*?)<\\|im_end\\|\\>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/re/__init__.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'Series'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_arc_text(text):\n",
        "    matches = re.findall(r\"<\\|im_start\\|\\>(.*?)\\n(.*?)<\\|im_end\\|\\>\", text, re.DOTALL)\n",
        "    messages = [{\"role\": role.strip(), \"content\": content.strip()} for role, content in matches]\n",
        "    return messages\n",
        "\n",
        "train_filtered = train_filtered.map(\n",
        "    lambda x: {\n",
        "        \"tokens\": tokenizer.apply_chat_template(\n",
        "            format_arc_text(x[\"text\"]),   # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=True\n",
        "        )\n",
        "    },\n",
        "    batched=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0b5cd75e9f574f58b6c93eaeffbae8eb",
            "05f6515594ef42eeb91ab5d5f28589ff",
            "bfb6505afc9549cebc2cf008e8c31e82",
            "221054bcd637455ca71897cd837e2517",
            "8e83fec516e54d40b0719977f97e860a",
            "a32a748f76cb4d30ba64faaa3220ef0e",
            "255788ca0eb64cea865ae56bcff7cb90",
            "12658761b73f444fa0a71f0f49204f9d",
            "aba74519d0fe4d099a5736528b2f68dc",
            "ad84b17910834f94a66e70a58cdf9831",
            "f4f26dacd3ff46d6bfb7b2e98b4454c7"
          ]
        },
        "id": "5oYIxgrZ4jEo",
        "outputId": "5f856845-3e93-4930-8925-4edf424660c2"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/876 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b5cd75e9f574f58b6c93eaeffbae8eb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_filtered = eval_filtered.map(\n",
        "    lambda x: {\n",
        "        \"tokens\": tokenizer.apply_chat_template(\n",
        "            format_arc_text(x[\"text\"]),   # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=True\n",
        "        )\n",
        "    },\n",
        "    batched=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "48824fd0b19a48d39864e8e991b5f6ee",
            "cec56c6ed23244d5b66908518d2cee25",
            "11677ddc6f174f3bb803e47d30dc6e20",
            "bdeb243a047b4ee398cc365a3ef23f50",
            "4b686160dc4f42bab07abb36468cd2ac",
            "8668e1a50bcd4a10a987c1d95145aad0",
            "5f83941ff3a241fc829219b679ed65c0",
            "9a1c113ea5eb421cb5048be45e427e10",
            "e502a32f06cc4d44a35c95a7c1a15b30",
            "788ac2aad2504570abee6331dd2eb62a",
            "64c5ef6fbb48475f8d97215a5210d64f"
          ]
        },
        "id": "TD_I0eBN5bQY",
        "outputId": "cfbc4b7c-178f-4a57-d5d9-5069aa5a13b2"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48824fd0b19a48d39864e8e991b5f6ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "maximum_length = int(np.quantile(train_filtered[\"L\"], 0.7))\n",
        "print(\"Max Length = \", maximum_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2auXL3Uo5h9h",
        "outputId": "62383dc7-6093-4207-f949-3ba5206b7209"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Length =  1739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "maximum_length_eval = int(np.quantile(eval_filtered[\"L\"], 0.2))\n",
        "print(\"Max Length = \", maximum_length_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h58ODbQW5ldb",
        "outputId": "1b90d003-bc1f-4289-d4fe-97eaf52ae763"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Length =  1703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_filtered_s = train_filtered.select(np.where(np.array(train_filtered[\"L\"]) <= maximum_length)[0])"
      ],
      "metadata": {
        "id": "3tmJHNnd5ycF"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_filtered_s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAT812Gz52z4",
        "outputId": "23d9cf22-5309-4c99-d29f-f996c0f9c5ff"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(614, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_filtered_s = eval_filtered.select(np.where(np.array(eval_filtered[\"L\"]) <= maximum_length_eval)[0])"
      ],
      "metadata": {
        "id": "dZcu80z159Bd"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_filtered_s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N19YCPVS8-dj",
        "outputId": "092bbd93-5a45-4c35-ae57-ddf2d42dea88"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ground_truth(example):\n",
        "    try:\n",
        "        # –ë–µ—Ä–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Ç—Ä–µ—Ç—å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (assistant)\n",
        "        answer = example[\"Messages\"][2][\"content\"]\n",
        "    except Exception:\n",
        "        answer = \"\"\n",
        "    return {\"answer\": answer}\n",
        "\n",
        "eval_filtered_s = eval_filtered_s.map(extract_ground_truth)\n",
        "train_filtered_s = train_filtered_s.map(extract_ground_truth)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "678dc67f04314e0dabcaa6b811472b0d",
            "9370bae869574a09a281d180c3a08d12",
            "e43c2948037348fa91ae5c8d130d7ab8",
            "fa9d1f0f42674bf2a80c938e65d73e86",
            "7b65715ba92448d498fb47c3f3d24216",
            "b48728e1432a411eac1b2cc2a85509a2",
            "f4a4990f3a084a9c990d26d3225dfdf1",
            "11a61423897940b9bbbfa90a7c88afd6",
            "bff96660b17d4be9aa5de298a6700dda",
            "c3c2339b7e6c4f429057d30efd7238b7",
            "2f52138b234e4f44bb80a4911e096ca9",
            "f6cbc56d6ea0446baa0293bacc226a5c",
            "23b5cb7d25044ca39621295ebe344e54",
            "b401b33c44c74cf2afa335dca6aead0a",
            "1d4c921ef6634ff39071ecc111c0c621",
            "c779810a7e5046e39870e715f474fdaa",
            "444424166766434381ac14412af2d5b0",
            "cd2157576ffa44ed96e9f3083ecb9d3a",
            "9ca6e698865f4774aa2711f6938969b5",
            "d0b2837f28e94bf1874c5ee25fb8c20b",
            "307485826de34718bee693443aba6ce8",
            "406ba4552d7e436c8dc0fdda8e1527a0"
          ]
        },
        "id": "V2cSzj9X99A3",
        "outputId": "b3017014-91a2-4e1c-e1a6-912d5cd24e28"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "678dc67f04314e0dabcaa6b811472b0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/614 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6cbc56d6ea0446baa0293bacc226a5c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_filtered_s[5][\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "aXUO22cp_b7D",
        "outputId": "4466187c-33da-464c-d5f9-79d855484731"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'### Output\\n\\n```grid shape: 12x13\\n1 0000000000000\\n2 0000000000000\\n3 0007022222000\\n4 0007000000244\\n5 0007022222000\\n6 0007000000000\\n7 0009000000000\\n8 0099000008000\\n9 0900900000800\\n10 0900900200082\\n11 0900900000800\\n12 0900900008000\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_prompt(example):\n",
        "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ system + user (–¥–æ assistant)\n",
        "    msgs = example[\"Messages\"]\n",
        "    prompt_msgs = [m for m in msgs if m[\"role\"] != \"assistant\"]\n",
        "    return tokenizer.apply_chat_template(prompt_msgs, add_generation_prompt=True, tokenize=False)\n",
        "\n",
        "train_filtered_s = train_filtered_s.map(lambda x: {\"prompt\": extract_prompt(x)})\n",
        "eval_filtered_s  = eval_filtered_s.map(lambda x: {\"prompt\": extract_prompt(x)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9507fbaeafca4a07aac7107a1d66decf",
            "0fbb611da1b747eb8a009b3e5506e253",
            "e45aa243fba2440f8b21e267f7c29453",
            "b949affac7bc4a29a955902a8272cbd4",
            "439a031c9a9c4b61a1cb08ea47fc486b",
            "5e4c3d59698d4e2dabb4c674a30a82b4",
            "79b3bfc7196a4e8298b53fae0cc7d41b",
            "3c00ba1dd64c4c50ac3eb595b40195a6",
            "bfdfdce6e65b4dcb93e50c1ed5a64036",
            "cf36325114db42378a3e5951c4ae8933",
            "f2dfd2eb120a443daa204a9eb4e61799",
            "85184cf4ddab42bf969987b7e44d4589",
            "33070c3b95f24f56b784fad27e0db3ff",
            "7c30371a535d4d9ea82e15465e129c0f",
            "33c9f06a99a8424bb59d784ef2d5efa0",
            "8d251ca343fc4436a0a6b009c716cb05",
            "d97d51ede39643f4a63500955b54af13",
            "e790343da0f84dff93041c7a6ff0252e",
            "239a7595ede44222b2c41c4859a06097",
            "ec95f1ae677c4d2398da474f4858a53d",
            "1edd986534fc42a6862c1fd9a4a49c7c",
            "c4115e53164e47f8a56f25931457213d"
          ]
        },
        "id": "uoLON1677ZFv",
        "outputId": "5f6d7475-a4c4-49f4-f883-1c038eadf4df"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/614 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9507fbaeafca4a07aac7107a1d66decf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85184cf4ddab42bf969987b7e44d4589"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_filtered_s[0][\"prompt\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "_EF6Vl5a7dLE",
        "outputId": "42fd98c2-51cd-4bd5-ca0f-1421acaeecce"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nLet's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 12x9\\n1 000000000\\n2 100100000\\n3 000000000\\n4 000000000\\n5 110000000\\n6 000000000\\n7 000000000\\n8 000000000\\n9 909000600\\n10 000000000\\n11 000000000\\n12 880000030\\n```\\n\\n### Output\\n\\n```grid shape: 12x9\\n1 000000000\\n2 100100100\\n3 000000000\\n4 000000000\\n5 111111111\\n6 000000000\\n7 000000000\\n8 000000000\\n9 606060600\\n10 000000000\\n11 000000000\\n12 333333330\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 9x20\\n1 00000000000000000000\\n2 00000000000000000000\\n3 00400000000000000000\\n4 00000000000000000050\\n5 00000000000000010000\\n6 00300000000000000000\\n7 00000000000000000090\\n8 00000000030000000000\\n9 00300000030000010090\\n```\\n\\n### Output\\n\\n```grid shape: 9x20\\n1 00000000030000010090\\n2 00000000030000000000\\n3 00400000030000000090\\n4 00000000030000000050\\n5 00000000030000010090\\n6 00400000030000000000\\n7 00000000030000000090\\n8 00000000030000000000\\n9 00400000030000010090\\n```\\n\\n## Example 3\\n\\n### Input\\n\\n```grid shape: 7x15\\n1 000000000000000\\n2 000000000000000\\n3 000000000000000\\n4 000000000000020\\n5 020000000000000\\n6 000002000600000\\n7 020002000600020\\n```\\n\\n### Output\\n\\n```grid shape: 7x15\\n1 020002000600020\\n2 000002000600000\\n3 020002000600000\\n4 000002000600020\\n5 020002000600000\\n6 000002000600000\\n7 020002000600020\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 9x21\\n1 000000000000000000000\\n2 000000000700000002002\\n3 000000900000000000055\\n4 000600000000000000022\\n5 000000000000000000000\\n6 000000000000010600006\\n7 000000000000000000000\\n8 000000000000000008008\\n9 000000040000000000707\\n```<|im_end|>\\n<|im_start|>assistant\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_filtered_s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P41lRk86Bu2",
        "outputId": "a10837ac-8e89-4d3e-b7e5-76379c2b64d7"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_idx = 0\n",
        "prompts = [eval_filtered_s[sample_idx][\"Messages\"][:-1]]  # system + user\n",
        "completions = [[{\"content\": \"### Output\\n```grid shape: 6x6\\n1 023232\\n2 787878\\n```\"}]]\n",
        "inputs = {\"answer\": [eval_filtered_s[sample_idx][\"answer\"]]}\n",
        "\n",
        "score = check_arc_overall(prompts, completions, inputs=inputs)\n",
        "print(\"Reward score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER7vJp1rAOUw",
        "outputId": "6ca828b0-2e23-4721-c813-250e8e6d959d"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUTS:\n",
            "{'answer': ['### Output\\n\\n```grid shape: 9x21\\n1 000000000000000000000\\n2 002002002702002002002\\n3 000000999999999999999\\n4 000666666666666666666\\n5 000000000000000000000\\n6 600006000060010600006\\n7 000000000000000000000\\n8 008008008008008008008\\n9 707070747070707070707\\n```']}\n",
            "ANSWERS:\n",
            "['### Output\\n\\n```grid shape: 9x21\\n1 000000000000000000000\\n2 002002002702002002002\\n3 000000999999999999999\\n4 000666666666666666666\\n5 000000000000000000000\\n6 600006000060010600006\\n7 000000000000000000000\\n8 008008008008008008008\\n9 707070747070707070707\\n```']\n",
            "DATA:\n",
            "[[{'content': 'You are a helpful assistant.', 'role': 'system'}, {'content': \"Let's see if you can solve this simple Abstraction and Reasoning Challenge (ARC) task.\\nBelow there are some input-output grid examples that define the task.\\nYour job is to understand the transformation between the input and the output and apply it to the test input grid.\\nThe transformations are always based on the following priors: objectness, goal-directed, numbers & counting, and basic geometry & topology.\\n\\n## Example 1\\n\\n### Input\\n\\n```grid shape: 12x9\\n1 000000000\\n2 100100000\\n3 000000000\\n4 000000000\\n5 110000000\\n6 000000000\\n7 000000000\\n8 000000000\\n9 909000600\\n10 000000000\\n11 000000000\\n12 880000030\\n```\\n\\n### Output\\n\\n```grid shape: 12x9\\n1 000000000\\n2 100100100\\n3 000000000\\n4 000000000\\n5 111111111\\n6 000000000\\n7 000000000\\n8 000000000\\n9 606060600\\n10 000000000\\n11 000000000\\n12 333333330\\n```\\n\\n## Example 2\\n\\n### Input\\n\\n```grid shape: 9x20\\n1 00000000000000000000\\n2 00000000000000000000\\n3 00400000000000000000\\n4 00000000000000000050\\n5 00000000000000010000\\n6 00300000000000000000\\n7 00000000000000000090\\n8 00000000030000000000\\n9 00300000030000010090\\n```\\n\\n### Output\\n\\n```grid shape: 9x20\\n1 00000000030000010090\\n2 00000000030000000000\\n3 00400000030000000090\\n4 00000000030000000050\\n5 00000000030000010090\\n6 00400000030000000000\\n7 00000000030000000090\\n8 00000000030000000000\\n9 00400000030000010090\\n```\\n\\n## Example 3\\n\\n### Input\\n\\n```grid shape: 7x15\\n1 000000000000000\\n2 000000000000000\\n3 000000000000000\\n4 000000000000020\\n5 020000000000000\\n6 000002000600000\\n7 020002000600020\\n```\\n\\n### Output\\n\\n```grid shape: 7x15\\n1 020002000600020\\n2 000002000600000\\n3 020002000600000\\n4 000002000600020\\n5 020002000600000\\n6 000002000600000\\n7 020002000600020\\n```\\n\\n## Test case\\n\\n### Input\\n\\n```grid shape: 9x21\\n1 000000000000000000000\\n2 000000000700000002002\\n3 000000900000000000055\\n4 000600000000000000022\\n5 000000000000000000000\\n6 000000000000010600006\\n7 000000000000000000000\\n8 000000000000000008008\\n9 000000040000000000707\\n```\", 'role': 'user'}]]\n",
            "[[{'content': '### Output\\n```grid shape: 6x6\\n1 023232\\n2 787878\\n```'}]]\n",
            "['### Output\\n\\n```grid shape: 9x21\\n1 000000000000000000000\\n2 002002002702002002002\\n3 000000999999999999999\\n4 000666666666666666666\\n5 000000000000000000000\\n6 600006000060010600006\\n7 000000000000000000000\\n8 008008008008008008008\\n9 707070747070707070707\\n```']\n",
            "Reward score: [3.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-IOMhVg-2AM"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "ptqkXK2D4d6p"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_prompt_length = maximum_length + 1\n",
        "max_completion_length = max_seq_length - max_prompt_length\n",
        "\n",
        "from vllm import SamplingParams\n",
        "vllm_sampling_params = SamplingParams(\n",
        "    min_p = 0.1,\n",
        "    top_p = 1.0,\n",
        "    top_k = -1,\n",
        "    seed = 3407,\n",
        "    stop = [tokenizer.eos_token],\n",
        "    include_stop_str_in_output = True,\n",
        ")\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    vllm_sampling_params = vllm_sampling_params,\n",
        "    temperature = 1.0,\n",
        "    learning_rate = 5e-6,\n",
        "    weight_decay = 0.01,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    per_device_train_batch_size = 4,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 4, # Decrease if out of memory\n",
        "    max_prompt_length = max_prompt_length,\n",
        "    max_completion_length = max_completion_length,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 100,\n",
        "    save_steps = 100,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # fp16_full_eval = True,\n",
        "    # per_device_eval_batch_size = 4,\n",
        "    # eval_accumulation_steps = 1,\n",
        "    # eval_strategy = \"steps\",\n",
        "    # eval_steps = 1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_filtered_s.column_names)\n",
        "print(train_filtered_s.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2peytCLAMGN",
        "outputId": "6eb4189e-8b25-46a2-d1eb-ddfe6e2df19a"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'ground_truth_output', 'Messages', 'tokens', 'L', 'answer', 'prompt']\n",
            "['text', 'Messages', 'tokens', 'L', 'answer', 'prompt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "76999300-c51a-4ddd-8409-f5e13a93e2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 614 | Num Epochs = 1 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 66,060,288 of 4,088,528,384 (1.62% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUTS:\n",
            "{}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'answer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3141797340.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# eval_dataset = new_dataset[\"test\"],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Return inference mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/extras/profiling.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mprofiling_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, generation_batch)\u001b[0m\n\u001b[1;32m   2011\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgenerate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m                 \u001b[0;31m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2013\u001b[0;31m                 \u001b[0mgeneration_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_and_score_completions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2014\u001b[0m                 \u001b[0mgeneration_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_pixel_values_by_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36m_generate_and_score_completions\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2423\u001b[0m         \u001b[0;31m# important because rewards will be normalized per group, and completions are distributed. We will later slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m         \u001b[0;31m# rewards_per_func to extract each process's subset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2425\u001b[0;31m         \u001b[0mrewards_per_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_rewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion_ids_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m         \u001b[0;31m# Apply weights to each reward function's output and sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/extras/profiling.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mprofiling_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36m_calculate_rewards\u001b[0;34m(self, inputs, prompts, completions, completion_ids_list)\u001b[0m\n\u001b[1;32m   2059\u001b[0m                         \u001b[0mrewards_per_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mreward_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Shape (B*G,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                     output_reward_func = reward_func(\n\u001b[0m\u001b[1;32m   2062\u001b[0m                         \u001b[0mprompts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompletion_ids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreward_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                     )\n",
            "\u001b[0;32m/tmp/ipython-input-2416306753.py\u001b[0m in \u001b[0;36mcheck_arc_overall\u001b[0;34m(prompts, completions, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INPUTS:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ANSWERS:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'answer'"
          ]
        }
      ],
      "source": [
        "# For optional training + evaluation\n",
        "# new_dataset = dataset.train_test_split(test_size = 0.01)\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        check_arc_overall\n",
        "    ],\n",
        "    reward_kwargs_field=\"answer\",\n",
        "    args = training_args,\n",
        "    train_dataset = train_filtered_s,\n",
        "    eval_dataset = eval_filtered_s\n",
        "\n",
        "    # For optional training + evaluation\n",
        "    # train_dataset = new_dataset[\"train\"],\n",
        "    # eval_dataset = new_dataset[\"test\"],\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtcz_lpbVC92"
      },
      "outputs": [],
      "source": [
        "text = \"What is the sqrt of 101?\"\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 1.0,\n",
        "    top_k = 50,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4LMOBl8boGX"
      },
      "source": [
        "Verify LoRA is actually trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SfdI-ERbpiw"
      },
      "outputs": [],
      "source": [
        "from safetensors import safe_open\n",
        "\n",
        "tensors = {}\n",
        "with safe_open(\"grpo_saved_lora/adapter_model.safetensors\", framework = \"pt\") as f:\n",
        "    # Verify both A and B are non zero\n",
        "    for key in f.keys():\n",
        "        tensor = f.get_tensor(key)\n",
        "        n_zeros = (tensor == 0).sum() / tensor.numel()\n",
        "        assert(n_zeros.item() != tensor.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwpbwnDBVRLg"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_OY5WMVOxF"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\",   \"content\": \"What is the sqrt of 101?\"},\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    tokenize = False,\n",
        ")\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 1.0,\n",
        "    top_k = 50,\n",
        "    max_tokens = 2048,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aDgFfhFYIAS"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjXGTkp7YNtB"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False:\n",
        "    model.save_pretrained(\"model\")\n",
        "    tokenizer.save_pretrained(\"model\")\n",
        "if False:\n",
        "    model.push_to_hub(\"hf/model\", token = \"\")\n",
        "    tokenizer.push_to_hub(\"hf/model\", token = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V15Yhj1V9lwG"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp.\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4a4b7f4c5dc248d4aa5455b154cc2933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3081f35f575f490c886563a4e1710ed1",
              "IPY_MODEL_6a411d787f6e446fa5c5b16a97498e3f",
              "IPY_MODEL_1708ff3764ad48818e66437321a1dc5c"
            ],
            "layout": "IPY_MODEL_04953d72c39844bcaf4e548c91ce6b82"
          }
        },
        "3081f35f575f490c886563a4e1710ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b08a8a584bf7415a9070112106bf559e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a9d3a9372b484d70a47eb79ffc32efd5",
            "value": ""
          }
        },
        "6a411d787f6e446fa5c5b16a97498e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8515b8dab98454384da95ba95a62a59",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_726cf36e1df04e719e9bbd6715845d7d",
            "value": 2
          }
        },
        "1708ff3764ad48818e66437321a1dc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18237675a20245e6afe80641f314d6f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e7dbc4d355224a99b196f82e3fe416e3",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá2/2‚Äá[00:37&lt;00:00,‚Äá18.14s/it]\n"
          }
        },
        "04953d72c39844bcaf4e548c91ce6b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b08a8a584bf7415a9070112106bf559e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d3a9372b484d70a47eb79ffc32efd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8515b8dab98454384da95ba95a62a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726cf36e1df04e719e9bbd6715845d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18237675a20245e6afe80641f314d6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7dbc4d355224a99b196f82e3fe416e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c05b8081956a49659a5a8e0ebfab3642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7b8bd11685c48f6b5cc725743243d63",
              "IPY_MODEL_0cd43bbdcc57491a8bcd2364ad058efb",
              "IPY_MODEL_9020651020e74c70b5b6880afd6ae3dd"
            ],
            "layout": "IPY_MODEL_1b62ca9855b04c38a6351c70f5784fd7"
          }
        },
        "b7b8bd11685c48f6b5cc725743243d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66631898cd848218e050004cf207cf3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8e3786321af4453aabe1331a56fe541a",
            "value": "Capturing‚ÄáCUDA‚Äágraph‚Äáshapes:‚Äá100%"
          }
        },
        "0cd43bbdcc57491a8bcd2364ad058efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81516ad9fe0485d9706ee23d0b7a126",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_920de4351a17413a8309e690288cbd14",
            "value": 27
          }
        },
        "9020651020e74c70b5b6880afd6ae3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb5bc0e3d1c648d3af048353263a95ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f22df68669f04d16865910aab04e3e5f",
            "value": "‚Äá27/27‚Äá[00:07&lt;00:00,‚Äá‚Äá2.76it/s]"
          }
        },
        "1b62ca9855b04c38a6351c70f5784fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66631898cd848218e050004cf207cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3786321af4453aabe1331a56fe541a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b81516ad9fe0485d9706ee23d0b7a126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920de4351a17413a8309e690288cbd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb5bc0e3d1c648d3af048353263a95ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22df68669f04d16865910aab04e3e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42f561905e7e4fcd9227a7ba7aca5bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f24cf098d014b11a3d1e96d5d263d0b",
              "IPY_MODEL_4a34fa8b5ffa455eadf57c13e5ebf64f",
              "IPY_MODEL_31f5c507625f4759910f64e103772d51"
            ],
            "layout": "IPY_MODEL_9d77372fecdc47249081f7327c7638a3"
          }
        },
        "6f24cf098d014b11a3d1e96d5d263d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde0b1358f2b49e4af519a9902670442",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3316354d566c4b64be8be80e29efe318",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"
          }
        },
        "4a34fa8b5ffa455eadf57c13e5ebf64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce594c09344843d4b2e6422fbe7afce6",
            "max": 46,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f72f37ea32654c4786fcf86c24d84e8e",
            "value": 46
          }
        },
        "31f5c507625f4759910f64e103772d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b298da760a4be4bdb0c1b40c3f7c69",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_da99ff7d57114391a9cfe09464961b83",
            "value": "‚Äá46/46‚Äá[00:04&lt;00:00,‚Äá15.24‚Äáexamples/s]"
          }
        },
        "9d77372fecdc47249081f7327c7638a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde0b1358f2b49e4af519a9902670442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3316354d566c4b64be8be80e29efe318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce594c09344843d4b2e6422fbe7afce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72f37ea32654c4786fcf86c24d84e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b298da760a4be4bdb0c1b40c3f7c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da99ff7d57114391a9cfe09464961b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b5cd75e9f574f58b6c93eaeffbae8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05f6515594ef42eeb91ab5d5f28589ff",
              "IPY_MODEL_bfb6505afc9549cebc2cf008e8c31e82",
              "IPY_MODEL_221054bcd637455ca71897cd837e2517"
            ],
            "layout": "IPY_MODEL_8e83fec516e54d40b0719977f97e860a"
          }
        },
        "05f6515594ef42eeb91ab5d5f28589ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32a748f76cb4d30ba64faaa3220ef0e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_255788ca0eb64cea865ae56bcff7cb90",
            "value": "Map:‚Äá100%"
          }
        },
        "bfb6505afc9549cebc2cf008e8c31e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12658761b73f444fa0a71f0f49204f9d",
            "max": 876,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aba74519d0fe4d099a5736528b2f68dc",
            "value": 876
          }
        },
        "221054bcd637455ca71897cd837e2517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad84b17910834f94a66e70a58cdf9831",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f4f26dacd3ff46d6bfb7b2e98b4454c7",
            "value": "‚Äá876/876‚Äá[00:03&lt;00:00,‚Äá307.69‚Äáexamples/s]"
          }
        },
        "8e83fec516e54d40b0719977f97e860a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32a748f76cb4d30ba64faaa3220ef0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255788ca0eb64cea865ae56bcff7cb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12658761b73f444fa0a71f0f49204f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba74519d0fe4d099a5736528b2f68dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad84b17910834f94a66e70a58cdf9831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f26dacd3ff46d6bfb7b2e98b4454c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48824fd0b19a48d39864e8e991b5f6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cec56c6ed23244d5b66908518d2cee25",
              "IPY_MODEL_11677ddc6f174f3bb803e47d30dc6e20",
              "IPY_MODEL_bdeb243a047b4ee398cc365a3ef23f50"
            ],
            "layout": "IPY_MODEL_4b686160dc4f42bab07abb36468cd2ac"
          }
        },
        "cec56c6ed23244d5b66908518d2cee25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8668e1a50bcd4a10a987c1d95145aad0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f83941ff3a241fc829219b679ed65c0",
            "value": "Map:‚Äá100%"
          }
        },
        "11677ddc6f174f3bb803e47d30dc6e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1c113ea5eb421cb5048be45e427e10",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e502a32f06cc4d44a35c95a7c1a15b30",
            "value": 111
          }
        },
        "bdeb243a047b4ee398cc365a3ef23f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788ac2aad2504570abee6331dd2eb62a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_64c5ef6fbb48475f8d97215a5210d64f",
            "value": "‚Äá111/111‚Äá[00:00&lt;00:00,‚Äá183.09‚Äáexamples/s]"
          }
        },
        "4b686160dc4f42bab07abb36468cd2ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8668e1a50bcd4a10a987c1d95145aad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f83941ff3a241fc829219b679ed65c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a1c113ea5eb421cb5048be45e427e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e502a32f06cc4d44a35c95a7c1a15b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "788ac2aad2504570abee6331dd2eb62a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c5ef6fbb48475f8d97215a5210d64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "678dc67f04314e0dabcaa6b811472b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9370bae869574a09a281d180c3a08d12",
              "IPY_MODEL_e43c2948037348fa91ae5c8d130d7ab8",
              "IPY_MODEL_fa9d1f0f42674bf2a80c938e65d73e86"
            ],
            "layout": "IPY_MODEL_7b65715ba92448d498fb47c3f3d24216"
          }
        },
        "9370bae869574a09a281d180c3a08d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48728e1432a411eac1b2cc2a85509a2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f4a4990f3a084a9c990d26d3225dfdf1",
            "value": "Map:‚Äá100%"
          }
        },
        "e43c2948037348fa91ae5c8d130d7ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a61423897940b9bbbfa90a7c88afd6",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bff96660b17d4be9aa5de298a6700dda",
            "value": 23
          }
        },
        "fa9d1f0f42674bf2a80c938e65d73e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c2339b7e6c4f429057d30efd7238b7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2f52138b234e4f44bb80a4911e096ca9",
            "value": "‚Äá23/23‚Äá[00:00&lt;00:00,‚Äá775.41‚Äáexamples/s]"
          }
        },
        "7b65715ba92448d498fb47c3f3d24216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48728e1432a411eac1b2cc2a85509a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a4990f3a084a9c990d26d3225dfdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11a61423897940b9bbbfa90a7c88afd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff96660b17d4be9aa5de298a6700dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3c2339b7e6c4f429057d30efd7238b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f52138b234e4f44bb80a4911e096ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6cbc56d6ea0446baa0293bacc226a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23b5cb7d25044ca39621295ebe344e54",
              "IPY_MODEL_b401b33c44c74cf2afa335dca6aead0a",
              "IPY_MODEL_1d4c921ef6634ff39071ecc111c0c621"
            ],
            "layout": "IPY_MODEL_c779810a7e5046e39870e715f474fdaa"
          }
        },
        "23b5cb7d25044ca39621295ebe344e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444424166766434381ac14412af2d5b0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd2157576ffa44ed96e9f3083ecb9d3a",
            "value": "Map:‚Äá100%"
          }
        },
        "b401b33c44c74cf2afa335dca6aead0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca6e698865f4774aa2711f6938969b5",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0b2837f28e94bf1874c5ee25fb8c20b",
            "value": 614
          }
        },
        "1d4c921ef6634ff39071ecc111c0c621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_307485826de34718bee693443aba6ce8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_406ba4552d7e436c8dc0fdda8e1527a0",
            "value": "‚Äá614/614‚Äá[00:00&lt;00:00,‚Äá4637.62‚Äáexamples/s]"
          }
        },
        "c779810a7e5046e39870e715f474fdaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444424166766434381ac14412af2d5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2157576ffa44ed96e9f3083ecb9d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca6e698865f4774aa2711f6938969b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b2837f28e94bf1874c5ee25fb8c20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "307485826de34718bee693443aba6ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "406ba4552d7e436c8dc0fdda8e1527a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9507fbaeafca4a07aac7107a1d66decf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fbb611da1b747eb8a009b3e5506e253",
              "IPY_MODEL_e45aa243fba2440f8b21e267f7c29453",
              "IPY_MODEL_b949affac7bc4a29a955902a8272cbd4"
            ],
            "layout": "IPY_MODEL_439a031c9a9c4b61a1cb08ea47fc486b"
          }
        },
        "0fbb611da1b747eb8a009b3e5506e253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4c3d59698d4e2dabb4c674a30a82b4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_79b3bfc7196a4e8298b53fae0cc7d41b",
            "value": "Map:‚Äá100%"
          }
        },
        "e45aa243fba2440f8b21e267f7c29453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c00ba1dd64c4c50ac3eb595b40195a6",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfdfdce6e65b4dcb93e50c1ed5a64036",
            "value": 614
          }
        },
        "b949affac7bc4a29a955902a8272cbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf36325114db42378a3e5951c4ae8933",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f2dfd2eb120a443daa204a9eb4e61799",
            "value": "‚Äá614/614‚Äá[00:00&lt;00:00,‚Äá4820.19‚Äáexamples/s]"
          }
        },
        "439a031c9a9c4b61a1cb08ea47fc486b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4c3d59698d4e2dabb4c674a30a82b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b3bfc7196a4e8298b53fae0cc7d41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c00ba1dd64c4c50ac3eb595b40195a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdfdce6e65b4dcb93e50c1ed5a64036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf36325114db42378a3e5951c4ae8933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2dfd2eb120a443daa204a9eb4e61799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85184cf4ddab42bf969987b7e44d4589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33070c3b95f24f56b784fad27e0db3ff",
              "IPY_MODEL_7c30371a535d4d9ea82e15465e129c0f",
              "IPY_MODEL_33c9f06a99a8424bb59d784ef2d5efa0"
            ],
            "layout": "IPY_MODEL_8d251ca343fc4436a0a6b009c716cb05"
          }
        },
        "33070c3b95f24f56b784fad27e0db3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97d51ede39643f4a63500955b54af13",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e790343da0f84dff93041c7a6ff0252e",
            "value": "Map:‚Äá100%"
          }
        },
        "7c30371a535d4d9ea82e15465e129c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239a7595ede44222b2c41c4859a06097",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec95f1ae677c4d2398da474f4858a53d",
            "value": 23
          }
        },
        "33c9f06a99a8424bb59d784ef2d5efa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1edd986534fc42a6862c1fd9a4a49c7c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c4115e53164e47f8a56f25931457213d",
            "value": "‚Äá23/23‚Äá[00:00&lt;00:00,‚Äá719.01‚Äáexamples/s]"
          }
        },
        "8d251ca343fc4436a0a6b009c716cb05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97d51ede39643f4a63500955b54af13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e790343da0f84dff93041c7a6ff0252e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "239a7595ede44222b2c41c4859a06097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec95f1ae677c4d2398da474f4858a53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1edd986534fc42a6862c1fd9a4a49c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4115e53164e47f8a56f25931457213d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}