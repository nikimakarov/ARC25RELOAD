#!/usr/bin/env python3
"""
–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–±–æ–ª—å—à–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Test-time Fine-tuning (TTFT)
–¥–ª—è —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è ARC25

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –¥–ª—è:
1. –°–æ–∑–¥–∞–Ω–∏—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ ARC –¥–∞—Ç–∞—Å–µ—Ç–∞
2. –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ N-1 –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è TTFT –æ–±—É—á–µ–Ω–∏—è
3. –í–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö

–ê–≤—Ç–æ—Ä: nikimakarov
–î–∞—Ç–∞: 2024
"""

import json
import random
import os
from typing import Dict, List, Tuple, Optional
from pathlib import Path


class TTFTDatasetCreator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è Test-time Fine-tuning
    """
    
    def __init__(self, random_seed: Optional[int] = 42):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞—Ç–µ–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        
        Args:
            random_seed: Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.random_seed = random_seed
        if random_seed is not None:
            random.seed(random_seed)
    
    def load_dataset(self, input_path: str) -> Dict:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ JSON —Ñ–∞–π–ª–∞
        
        Args:
            input_path: –ø—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∑–∞–¥–∞—á–∞–º–∏ ARC
        """
        try:
            with open(input_path, 'r') as f:
                data = json.load(f)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ {input_path}: {len(data)} –∑–∞–¥–∞—á")
            return data
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
            raise
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            raise
    
    def validate_task(self, task_id: str, task: Dict) -> bool:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–¥–∞—á–∏ ARC
        
        Args:
            task_id: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–¥–∞—á–∏
            task: –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
            
        Returns:
            True –µ—Å–ª–∏ –∑–∞–¥–∞—á–∞ –≤–∞–ª–∏–¥–Ω–∞, False –∏–Ω–∞—á–µ
        """
        required_keys = ['train', 'test']
        
        if not all(key in task for key in required_keys):
            print(f"‚ö†Ô∏è  –ó–∞–¥–∞—á–∞ {task_id} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏: {required_keys}")
            return False
        
        if not isinstance(task['train'], list) or len(task['train']) == 0:
            print(f"‚ö†Ô∏è  –ó–∞–¥–∞—á–∞ {task_id}: train –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º")
            return False
        
        if not isinstance(task['test'], list) or len(task['test']) == 0:
            print(f"‚ö†Ô∏è  –ó–∞–¥–∞—á–∞ {task_id}: test –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É train –ø—Ä–∏–º–µ—Ä–æ–≤
        for i, example in enumerate(task['train']):
            if not isinstance(example, dict) or 'input' not in example or 'output' not in example:
                print(f"‚ö†Ô∏è  –ó–∞–¥–∞—á–∞ {task_id}: train[{i}] –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'input' –∏ 'output'")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É test –ø—Ä–∏–º–µ—Ä–æ–≤
        for i, example in enumerate(task['test']):
            if not isinstance(example, dict) or 'input' not in example:
                print(f"‚ö†Ô∏è  –ó–∞–¥–∞—á–∞ {task_id}: test[{i}] –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'input'")
                return False
        
        return True
    
    def create_small_dataset(self, 
                           input_path: str, 
                           output_path: str, 
                           num_tasks: int = 5,
                           min_train_examples: int = 2) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö –∑–∞–¥–∞—á
        
        Args:
            input_path: –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
            output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
            num_tasks: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            min_train_examples: –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ train –ø—Ä–∏–º–µ—Ä–æ–≤
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        full_data = self.load_dataset(input_path)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        valid_tasks = {}
        for task_id, task in full_data.items():
            if (self.validate_task(task_id, task) and 
                len(task['train']) >= min_train_examples):
                valid_tasks[task_id] = task
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(valid_tasks)} –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–¥–∞—á –∏–∑ {len(full_data)}")
        
        if len(valid_tasks) < num_tasks:
            print(f"‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–¥–∞—á. –ó–∞–ø—Ä–æ—à–µ–Ω–æ: {num_tasks}, –¥–æ—Å—Ç—É–ø–Ω–æ: {len(valid_tasks)}")
            num_tasks = len(valid_tasks)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∑–∞–¥–∞—á–∏
        task_ids = list(valid_tasks.keys())
        selected_tasks = random.sample(task_ids, num_tasks)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        small_dataset = {task_id: valid_tasks[task_id] for task_id in selected_tasks}
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        self.save_dataset(small_dataset, output_path)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω –¥–∞—Ç–∞—Å–µ—Ç —Å {len(small_dataset)} –∑–∞–¥–∞—á–∞–º–∏:")
        for task_id in selected_tasks:
            task = small_dataset[task_id]
            print(f"  üìã {task_id}: {len(task['train'])} train, {len(task['test'])} test")
        
        return small_dataset
    
    def create_n_minus_1_dataset(self, data: Dict) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç N-1 –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è TTFT (–ø–µ—Ä–≤—ã–π train –ø—Ä–∏–º–µ—Ä —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è test)
        
        Args:
            data: –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            
        Returns:
            N-1 –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è TTFT
        """
        new_data = {}
        skipped_tasks = []
        
        for task_id, task in data.items():
            if len(task['train']) < 2:
                skipped_tasks.append(task_id)
                continue
            
            new_data[task_id] = {
                'train': task['train'][1:],  # –ë–µ—Ä–µ–º –≤—Å–µ train –ø—Ä–∏–º–µ—Ä—ã –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                'test': task['train'][:1],   # –ü–µ—Ä–≤—ã–π train –ø—Ä–∏–º–µ—Ä —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è "test"
            }
        
        if skipped_tasks:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ {len(skipped_tasks)} –∑–∞–¥–∞—á (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ train –ø—Ä–∏–º–µ—Ä–æ–≤): {skipped_tasks}")
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω N-1 –¥–∞—Ç–∞—Å–µ—Ç —Å {len(new_data)} –∑–∞–¥–∞—á–∞–º–∏")
        return new_data
    
    def save_dataset(self, data: Dict, output_path: str) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤ JSON —Ñ–∞–π–ª
        
        Args:
            data: –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w') as f:
            json.dump(data, f, indent=2)
        
        print(f"üíæ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    
    def create_ttft_test_datasets(self, 
                                input_path: str,
                                output_dir: str = ".",
                                num_tasks: int = 5,
                                min_train_examples: int = 2) -> Tuple[Dict, Dict]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è TTFT
        
        Args:
            input_path: –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
            num_tasks: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            min_train_examples: –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ train –ø—Ä–∏–º–µ—Ä–æ–≤
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (original_dataset, n_minus_1_dataset)
        """
        print("ÔøΩÔøΩ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è TTFT...")
        
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        small_output = os.path.join(output_dir, 'small_test_dataset.json')
        n_minus_1_output = os.path.join(output_dir, 'small_test_dataset_n-1.json')
        
        # –°–æ–∑–¥–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        small_dataset = self.create_small_dataset(
            input_path, small_output, num_tasks, min_train_examples
        )
        
        # –°–æ–∑–¥–∞–µ–º N-1 –≤–µ—Ä—Å–∏—é –¥–ª—è TTFT
        n_minus_1_dataset = self.create_n_minus_1_dataset(small_dataset)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º N-1 –¥–∞—Ç–∞—Å–µ—Ç
        self.save_dataset(n_minus_1_dataset, n_minus_1_output)
        
        print(f"\nüìÅ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}:")
        print(f"  - {os.path.basename(small_output)} (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç)")
        print(f"  - {os.path.basename(n_minus_1_output)} (N-1 –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è TTFT)")
        
        return small_dataset, n_minus_1_dataset


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    input_path = '/kaggle/input/arc-prize-2025/arc-agi_training_challenges.json'
    output_dir = '.'
    num_tasks = 5
    random_seed = 42
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–æ–∑–¥–∞—Ç–µ–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    creator = TTFTDatasetCreator(random_seed=random_seed)
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
        original_dataset, n_minus_1_dataset = creator.create_ttft_test_datasets(
            input_path=input_path,
            output_dir=output_dir,
            num_tasks=num_tasks,
            min_train_examples=2
        )
        
        print("\nÔøΩÔøΩ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:")
        print("1. small_test_dataset.json - –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        print("2. small_test_dataset_n-1.json - –¥–ª—è TTFT –æ–±—É—á–µ–Ω–∏—è")
        
        return original_dataset, n_minus_1_dataset
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {e}")
        raise


if __name__ == "__main__":
    main()